# httpx-rate-limiter-transport

![Python Badge](https://raw.githubusercontent.com/fabien-marty/common/refs/heads/main/badges/python310plus.svg)
[![UV Badge](https://raw.githubusercontent.com/fabien-marty/common/refs/heads/main/badges/uv.svg)](https://docs.astral.sh/uv/)
[![Mergify Badge](https://raw.githubusercontent.com/fabien-marty/common/refs/heads/main/badges/mergify.svg)](https://mergify.com/)
[![Renovate Badge](https://raw.githubusercontent.com/fabien-marty/common/refs/heads/main/badges/renovate.svg)](https://docs.renovatebot.com/)
[![MIT Licensed](https://raw.githubusercontent.com/fabien-marty/common/refs/heads/main/badges/mit.svg)](https://en.wikipedia.org/wiki/MIT_License)

## What is it?

This project provides an **async transport** for [httpx](https://www.python-httpx.org/) to implement various rate limiting (using a centralized redis as backend).

![](./docs/semaphore.png)

> [!NOTE]
> You can read some details about httpx transports on [this page](https://www.python-httpx.org/advanced/transports/).

## Features

- ✅ Limit the total number of concurrent outgoing requests (to any host)
- ✅ Limit the number of concurrent requests per host
- ✅ Provide your own logic/limit
    - for example: you can limit the number of concurrent requests by HTTP method or only for some given hosts...
- ✅ TTL to avoid blocking the semaphore forever (in some special cases like computer crash or network issues at the very wrong moment)
- ✅ Can wrap another transport (if you already use one)
- ✅ Multiple limits support
- ✅ Redis backend for distributed rate limiting

## Roadmap

- [ ] Add a "request per minute" rate limiting
- [x] Multiple limits
- [x] Logging
- [ ] Sync version

## Installation

`pip install httpx-rate-limiter-transport`

*(or the same with your favorite package manager)*

## Quickstart

Here's a simple example that demonstrates the basic usage:

```python
{{ "cat docs/quickstart.py"|shell() }}
```

**Expected behavior:** The requests will be rate-limited - only 1 request to google.com will execute at a time, even though we're trying to make 10 concurrent requests.

## How-to

<details>

<summary>How to get a concurrency limit for only one given host?</summary>

To get a concurrency limit only for a given host, you can use a `SingleHostConcurrencyRateLimit` limit object.

```python
{{ "cat docs/custom_concurrency_limit2.py"|shell() }}
```

</details>

<details>

<summary>How to implement your own custom logic?</summary>

You can use a `CustomConcurrencyRateLimit` object with a custom hook to implement your own logic.

If the hook returns None, this concurrency limit is deactivated. If the hook returns a key (as a string),
we count/limit the number of concurrent requests per distinct key.

```python
{{ "cat docs/custom_concurrency_limit1.py"|shell() }}
```

</details>

<details>

<summary>How to wrap another httpx transport?</summary>

If you already use a specific `httpx` transport, you can wrap it inside this one.

```python
{{ "cat docs/wrap.py"|shell() }}
```

</details>

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Install development dependencies: `make sync`
4. Run lint: `make lint`
5. Run tests: `make test`
6. Submit a pull request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
